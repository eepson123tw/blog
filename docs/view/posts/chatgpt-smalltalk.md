---
layout: doc
date: 2023-03-08 22:14:47
description: ChatGPT是甚麼?
title: ChatGPT 橫空出世，工程師該如何看待這現象?
---

最近幾周跟風，與同事一起玩ChatGPT並提問，越用越覺得強大，快速的回復速度加上極高的準確率，讓人不禁感嘆科技的躍進，也看到許多擔心自己會被AI取代的貼文，不禁思考起工程師這個職業真的這麼簡單會被AI取代嗎?

於是做了以下幾點，去分析ChatGPT，並展開這個議題

- ChatGPT是怎麼演化來的?
- 龐大的資料究竟怎麼收集?
- 他到底是使用甚麼模型?基於甚麼模式回答問題?
- 目前的瓶頸或是限制?
- 要以甚麼心態去看目前AI的趨勢?
- 要如何使用這項工具?

## ChatGPT是怎麼演化來的?

ChatGPT 是甚麼呢?

> ChatGPT是一個大型的自然語言(英文、日文、中文)處理模型，由OpenAI(微軟投資公司)開發和訓練。GPT代表"Generative Pre-trained Transformer"，它是一種基於Transformer架構的語言模型，可以根據先前的輸入文本預測下一個可能的文本。ChatGPT是一個特定版本的GPT模型，專門用於對話生成，它可以與人類進行自然而流暢的對話。

它是為了解決甚麼而誕生的?

> 為了解決對話中的自然語言理解、生成和流暢度等問題。基於大量文本數據訓練而成，並經過迭代演進，並非是2023年的新技術。2020年6月時就已經投入商業化，11月30日發佈。屬於AIGC(人工智能技術)的一部分，目前使用AI模型已迭代至GPT-3。

GPT基於**大規模化**(電腦的硬體提升、龐大的訓練資料1750億筆資料)、**Transformer架構**(自注意力機制的神經網絡架構，用於處理序列數據)、**轉移學習**(將已經學習到的知識、技術、能力，轉移至另外的一個新模型上，並應用)，分析輸入資料並使用**InstructGPT**(新型態的大型語言模型，旨在通過給出明確的指令或提示來生成自然語言文本)，來實現人類的意圖。

- GPT-1：

  1.發佈於2018年，是第一個使用Transformer架構的大型通用語言模型。2.以無監督方式在大量文本數據上訓練，能夠生成流暢的自然語言文本。3.使用12個Transformer編碼器層，共計110M個參數。4.在多種自然語言處理任務上取得了良好的表現。5.在發布當時被認為是目前最先進的語言模型之一。

---

- GPT-2：1.發佈於2019年，是GPT-1的升級版本，增加了模型大小和訓練數據量。2.使用了更多的Transformer編碼器層，共計1.5B個參數，是當時最大的語言模型之一。3.在多種自然語言處理任務上表現優異，能夠生成更長、更複雜、更具有邏輯性的文本。4.因為能夠生成高度可信的假新聞和惡意內容，所以引起了一些擔憂和爭議。5.需要更大的訓練數據和更強的正則化來解決生成有爭議文本的問題。

---

- GPT-3：1.發佈於2020年，是迄今為止最大的通用語言模型，擁有175B個參數。2.使用了更多的Transformer編碼器層和更大的訓練數據，能夠生成更自然、更真實、更多樣化的文本。3.在多種自然語言處理任務上取得了令人驚訝的表現，並且從未見過的應用也出現了。4.能夠快速進行零樣本、一樣本和少樣本學習，並且有能力進行多種語言的翻譯。5.然而，由於巨大的參數量和計算資源需求，GPT-3也面臨著可解釋性、隱私保護和環境影響等問題。

---

以上是GPT自行統正出的要點。

## 龐大的資料究竟怎麼收集?

OpenAI 開發了一個自動化的資料擷取程式，可以從各種網站上擷取文字資料，例如維基百科、新聞網站、社群媒體和書籍等等。擷取的資料包括了大量的自然語言文字，例如文章、評論、留言、社交媒體帖子等等。為了確保資料的品質，OpenAI 還使用了多種檢查和篩選機制，例如過濾掉低質量的網站、檢查資料的可信度和準確性等等。GPT-3還使用了多種公開的資料集和語言資源，例如Wikipedia、Common Crawl、BookCorpus等等，這些資料集包含大量的文本資料，可用於訓練模型並進行測試和驗證。

> 但仍需 人工標注的指令 和 提示資料集

## 到底是使用甚麼模型?基於甚麼模式回答問題?

ChatGPT基於GPT-3模型，無須監督學習，從大量的文本資料中回答詢問問題，透過輸入的資料(提問)與資料(175B參數)算出一個向量參數，也就是算目前的問題與這個資料的距離，若找到最近距離的資料，則有可能是解答，在極大量的資料下，這個距離可以縮短至相當近的距離，即正解。

> 可透過使用詞嵌入技術（Word Embedding）來實現，將每個單詞映射到一個高維向量空間中的一個向量，再將這些單詞向量結合起來，得到一個表示整個文本的向量。

## 目前的瓶頸或是限制?

1.回答的解答是否會違反知識產權? 2.回答的解答(來源)究竟是否有經過產出者的合意? 3.虛假訊息是否能高效的過濾，要用甚麼技術過濾?有誰能夠背書? 4.來源資料庫只到2021年，2022年後的趨勢及知識，無法提出回答。5.專業領域無法保證正確率，使用英文與中文提問，存在偏差。6.若非該領域熟悉者，無法分析此問題是否為該領域正確回答。

---

> 若指出錯誤，會馬上道歉，並給出建議，但建議有些是錯誤的(經過程式碼實測，例如請它做出輪播圖，卻有些參數漏了沒有給XD)

## 要以甚麼心態去看目前AI的趨勢?

不需用悲觀的角度去看目前的趨勢發展，有句俗語說 打不贏就加入，若已形成趨勢，趨勢就不易改變，生為工程師，我們可以觀測這些AI是否可以對我們的工作提出貢獻，對它產出的解答進行優化，加快我們的工作效率。工程師除了要寫程式碼有產出之外，雙向溝通(與User、PM、SA)、時程規劃、通靈(判斷需求是否可行)，都非一朝一夕，AI可以取代的，身為一個技術職位，我們豈能跟新技術保持距離呢?說不定還能用AI寫個專案，發個大財呢~(開玩笑XD)，保持警覺吸取產業新知，並觀察是否有順風車可以搭乘，提升自己的技術力與薪資(出來混還是要討口飯吃的)

## 要如何使用這項工具?

基於觀察及體驗的角度，以下是個人一些提問上的統整。

1.若提問領域英文為主，就盡量用英文提問。2.提問可以層層提問，先由一個基礎問題，再慢慢發展，可以有更全面的認知。3.若是一個廣泛的問題，可以先以問題的核心開始提問。4.若回答相當的大量，可以設定角色回答。(我是一個高中生，請以我能聽懂的程度回答......) 5.縮減回答至關鍵要點(統整出簡單要點，10點每點50字內，等等...) 6.若是專業問題，可以改為專有名詞回答(使用XXX模型回答，導入某某格式，參考XXX名言等等...) 7.可以複製文章請它找出重點並由重點延伸回答。

---

提供幾個好用的英文單句

```txt
Topics about X for the future ⇒ 用於未來式
Please elaborate more on XXX ⇒ 更加細化的分享某領域(展開)
Please recommend some methods or books ⇒ 推薦該領域實際書籍或方法
term project ,portfolio(學習歷程) ⇒ 可以設計出一段時間的學習歷程
Summary 最基礎的摘要
Plot 基本的情節
Detailed synopsis 概要(synopsis)
Quotes 直接抓出最值得參考的
With example 與範例一起顯示 ⇒ discussion questions for XXX with example answers
Table Topics ⇒ 表格話題
similar plots ⇒ 類似情節
```

若有更好的使用模式，也請提供給我喔~~

- [OpenAI wiki](https://zh.wikipedia.org/zh-tw/OpenAI)
- [ChatGPT研究框架2023](https://www.slidestalk.com/ai_algorithms/ChatGPT20232023277231656)
- [What Is It and How Does It Work?](https://www.entrepreneur.com/science-technology/chatgpt-what-is-it-and-how-does-it-work/445014)
- [ChatGPT 未來式：從語言學習延伸到日常工作的高效 AI 工具](https://shop.wordup.com.tw/product/1022)

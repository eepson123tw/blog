---
title: AI Help Me Out
description: RAG, Embedding, Agent
icon: 'lucide:rotate-3d'
gitTalk: true
date: 2025-02-02 12:07:00
read: '10'
authors:
  - name: Aaron Shih
    username: eepson123tw
    avatar: https://www.github.com/eepson123tw.png
    to: https://github.com/eepson123tw
    target: _blank
badges:
  - value: This field is evolving rapidly; information may change
---

After attending [webconf 2024](https://webconf.tw/) with some of my former colleagues, we noticed that although a few AI-related keywords were mentioned in the talks, most people still had a vague understanding of what AI is actually capable of.

They asked me if I could write a post to explain some of the concepts, so I created this slide deck.

::alert{to="https://ai-hurry-up.zeabur.app" type="info" target="_blank" icon="lucide:link"}
  AI Help Me Out â€“ ai-hurry-up
::

The slides cover concepts like RAG, Embedding, and Tool Usage.
They also briefly introduce the current trends, practical applications, where to find different models, andâ€”most importantlyâ€”**learning resources and methods**.

A video version will be uploaded to YouTube later (hopefully it wonâ€™t be too awkward ðŸ« ).

This article highlights a few key points from the slides.

## LLM â€“ Large Language Models

Large Language Models (LLMs) are deep learning modelsâ€”especially based on the Transformer architectureâ€”trained to understand, generate, and process natural language text. These models are usually pre-trained on massive datasets to learn statistical patterns and semantic structures in language.

Examples include GPT, Gemini, LLaMA, etc.

## Embedding â€“ Vector Representations

Have you ever wondered how a model can understand various types of input like text, images, or video?

Itâ€™s because of **embedding**, which converts diverse data types into **vectors**â€”numerical representations in multi-dimensional space.

![embedding](/images/ai/embedding.png)

Still sounds a bit abstract?

Think of it this way: when you hear the word â€œdog,â€ you immediately imagine how a dog looks or sounds. Thatâ€™s because your brain has built a kind of "embedding" that links the word to a concept.

Embeddings do the sameâ€”they connect text, sound, and visuals through mathematical relationships.

Check out [ai-hurry-up](https://ai-hurry-up.zeabur.app/8) for some fun examples you can try!

## RAG â€“ Retrieval-Augmented Generation

![RAG](/images/ai/rag.png)

RAG is a complex topicâ€”actually, itâ€™s more of a **framework**. It uses embeddings to transform your data and store it in a **vector database**.

Yes, traditional databases canâ€™t handle these transformed vectors, as they're just long sequences of numbers. Using SQL on them wouldnâ€™t be meaningful, especially for finding semantic matches. That's why we use **specialized vector databases**.

RAG allows an LLM to search relevant vectorized information **before** generating a response.

### What Problem Does RAG Solve?

LLMs often give off-topic answers or hallucinate factsâ€”theyâ€™re not aware of real-time or domain-specific data.

RAG solves this by allowing the model to **retrieve relevant data first**, then answer based on it.

### Challenges of RAG

- Input size limitations
- Parsing speed
- Complexity of vector databases
- Data filtering

Even with these challenges, RAG is being adopted rapidly.

Tools like **Gmail Gemini** and **Notion AI** already incorporate RAG.
Some even propose newer frameworks like **CAG**.

## Agent â€“ AI Agents

This refers to AI systems that can make decisions and take actions independently. In short, it means giving an LLM the ability to use **tools** to complete tasks assigned by humans.

![n8n](/images/ai/n8n.png)

For example, in the image above I used **n8n** (a free, open-source workflow automation tool) to connect to GPT-4o. I had it parse the AI tech emails I subscribe to daily, extract the key points, and send them back to me.

![n8n summarization](/images/ai/n8n_summarization.png)

Of course, this is just a simple demoâ€”real-world use cases can be much more complex.

::alert{ type="success" target="_blank" icon="lucide:badge-alert"}
  Who knows? Maybe one day weâ€™ll have **Engineer Agents** ðŸ˜ˆ
::

## Summary

Using simple language, this post introduces several trending AI concepts to help you understand what these technologies can actually do:

- **LLM â€“ Large Language Models**
> Like a super brain that can chat with you. It understands and generates natural language so we can interact with computers in human language. Examples: GPT, Gemini, LLaMA.

- **Embedding â€“ Vector Representations**
> Imagine how hearing â€œdogâ€ instantly brings up images and sounds in your mind. AI does this too, by turning various data (text, images, audio) into numeric vectors so computers can understand and connect them.

- **RAG â€“ Retrieval-Augmented Generation**
> Sometimes LLMs give wrong or random answers. RAG helps by retrieving the right info first and generating answers based on that, improving accuracy and relevance.

- **Agent â€“ AI Agent Systems**
> Think of it as a super helper that can decide what to do, how to do it, and which tools to useâ€”like letting an AI auto-summarize your emails every day using tools like n8n.

## Reference

- [What Are Embeddings â€“ Qdrant](https://qdrant.tech/articles/what-are-embeddings/)
- [What is RAG â€“ AWS](https://aws.amazon.com/tw/what-is/retrieval-augmented-generation/)
